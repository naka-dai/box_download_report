"""
Box Daily Update - All-in-One Script
ãƒ‡ãƒ¼ã‚¿åé›†ã¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆã‚’1ã¤ã«ã¾ã¨ã‚ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆ

å®Ÿè¡Œé †åº:
1. User Activity CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
2. Box APIã‹ã‚‰æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦SQLiteã«ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
3. æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ããƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
4. Netlifyã¸ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
"""

import sys
import os
import subprocess
import shutil
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# Load .env from the same directory as this script/exe
if getattr(sys, 'frozen', False):
    # Running as compiled exe
    application_path = os.path.dirname(sys.executable)
else:
    # Running as script
    application_path = os.path.dirname(os.path.abspath(__file__))

env_path = os.path.join(application_path, '.env')
print(f"[DEBUG] Application path: {application_path}")
print(f"[DEBUG] Looking for .env at: {env_path}")
if os.path.exists(env_path):
    load_dotenv(env_path, override=True)
    print(f"[INFO] Loaded .env from: {env_path}")
    print(f"[DEBUG] DB_PATH from env: {os.getenv('DB_PATH')}")
    print(f"[DEBUG] SKIP_DATA_COLLECTION: {os.getenv('SKIP_DATA_COLLECTION')}")
    print(f"[DEBUG] SKIP_GITHUB_PUSH: {os.getenv('SKIP_GITHUB_PUSH')}")
else:
    print(f"[WARNING] .env not found at: {env_path}")
    load_dotenv(override=True)  # Try default behavior


def run_git_command(cmd: list, cwd: Path = None) -> tuple[int, str]:
    """Run git command and return (returncode, output)."""
    try:
        result = subprocess.run(
            cmd,
            cwd=cwd or Path.cwd(),
            capture_output=True,
            text=True,
            encoding='utf-8',
            check=False
        )
        return result.returncode, result.stdout + result.stderr
    except Exception as e:
        return 1, str(e)


def push_to_github(dashboard_path: Path, repo_root: Path) -> bool:
    """
    Push dashboard to GitHub Pages.

    Args:
        dashboard_path: Path to dashboard HTML file
        repo_root: Path to repository root

    Returns:
        True if successful, False otherwise
    """
    # Check if we're in a git repository
    returncode, _ = run_git_command(['git', 'rev-parse', '--git-dir'], repo_root)
    if returncode != 0:
        print("[INFO] Not in a git repository. Skipping GitHub push.")
        return False

    # Check if dashboard file exists
    if not dashboard_path.exists():
        print(f"[WARNING] Dashboard file not found: {dashboard_path}")
        return False

    print("\n[ã‚¹ãƒ†ãƒƒãƒ—3] GitHub Pagesã¸ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ãƒ—ãƒƒã‚·ãƒ¥ä¸­...")
    print("-" * 80)

    try:
        # Get current branch
        returncode, output = run_git_command(['git', 'branch', '--show-current'], repo_root)
        if returncode != 0:
            print(f"[WARNING] Failed to get current branch: {output}")
            return False

        current_branch = output.strip()
        print(f"[INFO] Current branch: {current_branch}")

        # Stash any uncommitted changes
        if current_branch != "gh-pages":
            print("[INFO] Stashing uncommitted changes...")
            run_git_command(['git', 'stash', 'push', '-m', 'Auto-stash before dashboard update'], repo_root)

        # Checkout gh-pages branch
        print("[INFO] Switching to gh-pages branch...")
        returncode, output = run_git_command(['git', 'checkout', 'gh-pages'], repo_root)
        if returncode != 0:
            print(f"[WARNING] Failed to checkout gh-pages: {output}")
            print("[INFO] gh-pages branch may not exist. Skipping GitHub push.")
            run_git_command(['git', 'checkout', current_branch], repo_root)
            return False

        # Copy dashboard to index.html in repo root
        target_path = repo_root / "index.html"
        print(f"[INFO] Copying dashboard to {target_path}...")
        shutil.copy2(dashboard_path, target_path)

        # Update README with timestamp
        readme_path = repo_root / "README.md"
        if readme_path.exists():
            with open(readme_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # Update timestamp in README
            import re
            timestamp = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
            content = re.sub(
                r'æœ€çµ‚æ›´æ–°: \d{4}å¹´\d{2}æœˆ\d{2}æ—¥ \d{2}:\d{2}:\d{2}',
                f'æœ€çµ‚æ›´æ–°: {timestamp}',
                content
            )

            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print("[INFO] README updated")

        # Stage changes
        print("[INFO] Staging changes...")
        run_git_command(['git', 'add', 'index.html', 'README.md'], repo_root)

        # Commit
        commit_msg = f"""Update dashboard - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
"""
        print("[INFO] Committing changes...")
        returncode, output = run_git_command(['git', 'commit', '-m', commit_msg], repo_root)
        if returncode != 0:
            print(f"[WARNING] Failed to commit: {output}")
            run_git_command(['git', 'checkout', current_branch], repo_root)
            return False

        # Push to GitHub
        print("[INFO] Pushing to GitHub...")
        returncode, output = run_git_command(['git', 'push', 'origin', 'gh-pages'], repo_root)
        if returncode != 0:
            print(f"[WARNING] Failed to push to GitHub: {output}")
            print("[INFO] ã‚³ãƒŸãƒƒãƒˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        else:
            print("[OK] GitHub Pagesã¸ã®ãƒ—ãƒƒã‚·ãƒ¥å®Œäº†")
            print("     URL: https://naka-dai.github.io/box_download_report/")

        # Switch back to original branch
        print(f"[INFO] Switching back to {current_branch} branch...")
        run_git_command(['git', 'checkout', current_branch], repo_root)

        # Pop stash if exists
        if current_branch != "gh-pages":
            run_git_command(['git', 'stash', 'pop'], repo_root)

        return returncode == 0

    except Exception as e:
        print(f"[ERROR] GitHub push failed: {e}")
        import traceback
        traceback.print_exc()
        # Try to restore original state
        run_git_command(['git', 'checkout', current_branch], repo_root)
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 80)
    print("Box Daily Update - ãƒ‡ãƒ¼ã‚¿åé›†ã¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆ")
    print(f"é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
    print("=" * 80)

    # ã‚¹ãƒ†ãƒƒãƒ—0: User Activity CSVã‚’Box APIã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    skip_csv_import = os.getenv("SKIP_CSV_IMPORT", "").lower() in ("1", "true", "yes")

    if skip_csv_import:
        print("\n[ã‚¹ãƒ†ãƒƒãƒ—0] CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ— (SKIP_CSV_IMPORT=1)")
        print("-" * 80)
    else:
        print("\n[ã‚¹ãƒ†ãƒƒãƒ—0] User Activity CSVã‚’Box APIã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­...")
        print("-" * 80)

        try:
            from db import Database
            from csv_importer import CSVImporter
            from csv_downloader import CSVDownloader
            from box_client import BoxClient

            # Box APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
            print("[INFO] Box APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ä¸­...")
            config_path = os.getenv("BOX_CONFIG_PATH", "config.json")
            box_client = BoxClient(config_path)

            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆ: EXEãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€/data
            csv_downloader = CSVDownloader(box_client)

            # Box Reports ãƒ•ã‚©ãƒ«ãƒ€IDã‚’å–å¾—
            box_reports_folder_id = os.getenv("BOX_ROOT_FOLDER_ID", "248280918136")

            # æœ€æ–°ã®User Activity ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            print(f"[INFO] Box Reports ãƒ•ã‚©ãƒ«ãƒ€ (ID: {box_reports_folder_id}) ã‹ã‚‰æœ€æ–°ã®User Activity CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            csv_files = csv_downloader.download_latest_user_activity_csvs(box_reports_folder_id)

            if csv_files:
                print(f"[OK] {len(csv_files)}å€‹ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                db_path = os.getenv("DB_PATH", "C:\\box_reports\\box_audit.db")
                with Database(db_path) as db:
                    importer = CSVImporter(db)
                    imported_count = importer.import_multiple_csvs(csv_files)
                    print(f"[OK] CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {imported_count:,}ä»¶ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
            else:
                print("[WARNING] CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
                print("[INFO] Box APIã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«é€²ã¿ã¾ã™")

        except Exception as e:
            print(f"[WARNING] CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰/ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print("[INFO] Box APIã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«é€²ã¿ã¾ã™")
            import traceback
            traceback.print_exc()

    # ã‚¹ãƒ†ãƒƒãƒ—1: Box APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿åé›†
    skip_data_collection = os.getenv("SKIP_DATA_COLLECTION", "").lower() in ("1", "true", "yes")

    if skip_data_collection:
        print("\n[ã‚¹ãƒ†ãƒƒãƒ—1] Box APIã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿åé›†ã‚’ã‚¹ã‚­ãƒƒãƒ— (SKIP_DATA_COLLECTION=1)")
        print("-" * 80)
        print("[INFO] æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã™")
    else:
        print("\n[ã‚¹ãƒ†ãƒƒãƒ—1] Box APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...")
        print("-" * 80)

        try:
            # main.pyã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦å®Ÿè¡Œ
            import main as data_collector
            data_collector.main()
            print("[OK] ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")

        except Exception as e:
            print(f"[WARNING] ãƒ‡ãƒ¼ã‚¿åé›†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print("[INFO] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆã‚’ç¶šè¡Œã—ã¾ã™ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰")
            import traceback
            traceback.print_exc()

    # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆ
    print("\n[ã‚¹ãƒ†ãƒƒãƒ—2] æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ããƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆä¸­...")
    print("-" * 80)

    try:
        # generate_period_allinone_full.pyã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦å®Ÿè¡Œ
        import generate_period_allinone_full as dashboard_generator
        dashboard_generator.generate_dashboard()
        print("[OK] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆå®Œäº†")

    except Exception as e:
        print(f"[ERROR] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return 1

    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ãƒ‘ã‚¹ã‚’å–å¾—
    dashboard_output_dir = os.getenv("REPORT_OUTPUT_DIR", "C:\\box_reports")
    dashboard_path = Path(dashboard_output_dir) / "dashboard_period_allinone_full.html"

    # ã‚¹ãƒ†ãƒƒãƒ—2.5: ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    alert_enabled = os.getenv("ALERT_ENABLED", "").lower() in ("1", "true", "yes")

    if alert_enabled:
        print("\n[ã‚¹ãƒ†ãƒƒãƒ—2.5] ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œçŸ¥ä¸­...")
        print("-" * 80)
        try:
            from config import Config
            from db import Database
            from anomaly import AnomalyDetector
            from aggregator import DataAggregator
            from reporter import CSVReporter
            from mailer import Mailer

            config = Config()
            db_path = os.getenv("DB_PATH", "C:\\box_reports\\box_audit.db")

            # å‰æ—¥ã®æ—¥ä»˜ï¼ˆBoxã®CSVã¯å‰æ—¥åˆ†ãŒç¿Œæ—¥ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚Œã‚‹ãŸã‚ï¼‰
            from datetime import timedelta
            yesterday = datetime.now() - timedelta(days=1)
            date_str = yesterday.strftime("%Y%m%d")
            yesterday_str_hyphen = yesterday.strftime("%Y-%m-%d")
            period_type = "daily"

            # ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡å±¥æ­´ã‚’ç¢ºèªï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
            with Database(db_path) as db:
                db.initialize_tables()  # alert_historyãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç¢ºå®Ÿã«ä½œæˆ
                alert_already_sent = db.check_alert_sent(yesterday_str_hyphen, period_type)
                alert_already_uploaded = db.check_alert_uploaded(yesterday_str_hyphen, period_type)

            if alert_already_sent and alert_already_uploaded:
                print(f"[INFO] {yesterday_str_hyphen}ã®ã‚¢ãƒ©ãƒ¼ãƒˆã¯æ—¢ã«é€ä¿¡ãƒ»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã§ã™ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            else:
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å‰æ—¥ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—
                with Database(db_path) as db:
                    yesterday_str = yesterday.strftime("%Y-%m-%d")
                    today_str = datetime.now().strftime("%Y-%m-%d")
                    events = db.get_downloads_by_period(yesterday_str, today_str)

                if not events:
                    print(f"[INFO] å‰æ—¥({yesterday_str})ã®ã‚¤ãƒ™ãƒ³ãƒˆãŒãªã„ãŸã‚ã€ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                else:
                    print(f"[INFO] å‰æ—¥({yesterday_str})ã®ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(events)}")

                    # é›†è¨ˆ
                    aggregator = DataAggregator()
                    user_stats = aggregator.aggregate_by_user(events)

                    # é™¤å¤–ãƒ¦ãƒ¼ã‚¶ãƒ¼
                    excluded_users = config.get_alert_exclude_users()

                    # ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œçŸ¥
                    detector = AnomalyDetector(
                        download_count_threshold=config.ALERT_USER_DOWNLOAD_COUNT_THRESHOLD,
                        unique_files_threshold=config.ALERT_USER_UNIQUE_FILES_THRESHOLD,
                        offhour_threshold=config.ALERT_OFFHOUR_DOWNLOAD_THRESHOLD,
                        spike_window_minutes=config.ALERT_SPIKE_WINDOW_MINUTES,
                        spike_threshold=config.ALERT_SPIKE_DOWNLOAD_THRESHOLD,
                        excluded_users=excluded_users
                    )

                    # å–¶æ¥­æ™‚é–“å¤–ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    bh_start_hour, bh_start_min, bh_end_hour, bh_end_min = config.get_business_hours_range()
                    offhour_counts = aggregator.count_offhour_downloads_by_user(
                        events, bh_start_hour, bh_start_min, bh_end_hour, bh_end_min
                    )

                    # ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œçŸ¥å®Ÿè¡Œ
                    anomalous_users = detector.detect_all_anomalies(user_stats, offhour_counts)

                    if not anomalous_users:
                        print("[INFO] ã‚¢ãƒ©ãƒ¼ãƒˆå¯¾è±¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã„ã¾ã›ã‚“")
                    else:
                        print(f"[WARNING] {len(anomalous_users)}äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã‚¢ãƒ©ãƒ¼ãƒˆã‚’æ¤œçŸ¥")

                        # ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
                        anomaly_summary = detector.get_anomaly_summary(anomalous_users)
                        print(anomaly_summary)

                        # é‡å¤§åº¦ã‚’è¨ˆç®—ï¼ˆé–¾å€¤ã®ä½•å€ã‹ã‚’è¨ˆç®—ï¼‰
                        max_ratio = 1.0
                        for email, user_data in anomalous_users.items():
                            if user_data.get('download_count', 0) > 0 and config.ALERT_USER_DOWNLOAD_COUNT_THRESHOLD > 0:
                                ratio = user_data['download_count'] / config.ALERT_USER_DOWNLOAD_COUNT_THRESHOLD
                                max_ratio = max(max_ratio, ratio)
                            if user_data.get('unique_files_count', 0) > 0 and config.ALERT_USER_UNIQUE_FILES_THRESHOLD > 0:
                                ratio = user_data['unique_files_count'] / config.ALERT_USER_UNIQUE_FILES_THRESHOLD
                                max_ratio = max(max_ratio, ratio)
                            if user_data.get('offhour_downloads', 0) > 0 and config.ALERT_OFFHOUR_DOWNLOAD_THRESHOLD > 0:
                                ratio = user_data['offhour_downloads'] / config.ALERT_OFFHOUR_DOWNLOAD_THRESHOLD
                                max_ratio = max(max_ratio, ratio)

                        # é‡å¤§åº¦ãƒ¬ãƒ™ãƒ«ã‚’æ±ºå®š
                        if max_ratio >= 10:
                            severity = 'critical'
                            print(f"[ALERT] *** é‡å¤§åº¦: ç·Šæ€¥ï¼ˆé–¾å€¤ã® {max_ratio:.1f} å€è¶…éï¼‰***")
                        elif max_ratio >= 5:
                            severity = 'high'
                            print(f"[ALERT] * é‡å¤§åº¦: è­¦å‘Šï¼ˆé–¾å€¤ã® {max_ratio:.1f} å€è¶…éï¼‰")
                        else:
                            severity = 'normal'
                            print(f"[INFO] é‡å¤§åº¦: é€šå¸¸ï¼ˆé–¾å€¤ã® {max_ratio:.1f} å€è¶…éï¼‰")

                        severity_info = {'level': severity, 'max_ratio': max_ratio}

                        # CSVãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                        reporter = CSVReporter(config.ANOMALY_OUTPUT_DIR)
                        anomaly_csv_path = reporter.write_anomaly_details(
                            anomalous_users, date_str, period_type,
                            config.ANOMALY_OUTPUT_DIR, max_rows=config.ALERT_ATTACHMENT_MAX_ROWS
                        )
                        print(f"[INFO] ã‚¢ãƒ©ãƒ¼ãƒˆè©³ç´°CSV: {anomaly_csv_path}")

                        # ãƒ¡ãƒ¼ãƒ«é€ä¿¡ï¼ˆæœªé€ä¿¡ã®å ´åˆã®ã¿ï¼‰
                        if not alert_already_sent:
                            try:
                                mailer = Mailer(
                                    smtp_host=config.SMTP_HOST,
                                    smtp_port=config.SMTP_PORT,
                                    smtp_user=config.SMTP_USER,
                                    smtp_password=config.SMTP_PASSWORD,
                                    use_tls=config.SMTP_USE_TLS
                                )
                                to_addrs = config.get_mail_to_list()
                                success = mailer.send_anomaly_alert(
                                    from_addr=config.ALERT_MAIL_FROM,
                                    to_addrs=to_addrs,
                                    subject_prefix=config.ALERT_MAIL_SUBJECT_PREFIX,
                                    date_str=f"{date_str} ({period_type})",
                                    anomaly_summary=anomaly_summary,
                                    attachment_paths=[anomaly_csv_path],
                                    severity_info=severity_info
                                )
                                if success:
                                    print("[OK] ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¡ãƒ¼ãƒ«é€ä¿¡å®Œäº†")
                                    # é€ä¿¡å±¥æ­´ã‚’è¨˜éŒ²
                                    with Database(db_path) as db:
                                        db.record_alert_sent(yesterday_str_hyphen, period_type,
                                                           len(anomalous_users), anomaly_csv_path)
                                else:
                                    print("[ERROR] ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¡ãƒ¼ãƒ«é€ä¿¡å¤±æ•—")
                            except Exception as e:
                                print(f"[ERROR] ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
                                import traceback
                                traceback.print_exc()
                        else:
                            print(f"[INFO] {yesterday_str_hyphen}ã®ãƒ¡ãƒ¼ãƒ«ã¯æ—¢ã«é€ä¿¡æ¸ˆã¿ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")

                        # Boxã«CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæœªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã®ã¿ï¼‰
                        if not alert_already_uploaded:
                            anomaly_log_folder_id = os.getenv("ANOMALY_LOG_FOLDER_ID", "353439076724")
                            if anomaly_log_folder_id:
                                try:
                                    from box_client import BoxClient
                                    box_config_path = os.path.join(application_path, os.getenv("BOX_CONFIG_PATH", "config.json"))
                                    box_client = BoxClient(box_config_path)
                                    uploaded_file_id = box_client.upload_file(
                                        folder_id=anomaly_log_folder_id,
                                        file_path=anomaly_csv_path
                                    )
                                    if uploaded_file_id:
                                        print(f"[OK] Boxã«CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº† (ãƒ•ã‚©ãƒ«ãƒ€ID: {anomaly_log_folder_id}, ãƒ•ã‚¡ã‚¤ãƒ«ID: {uploaded_file_id})")
                                        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å±¥æ­´ã‚’è¨˜éŒ²
                                        with Database(db_path) as db:
                                            db.record_alert_uploaded(yesterday_str_hyphen, period_type, uploaded_file_id)
                                    else:
                                        print("[ERROR] Boxã¸ã®CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—")
                                except Exception as box_e:
                                    print(f"[ERROR] Boxã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {box_e}")
                                    import traceback
                                    traceback.print_exc()
                        else:
                            print(f"[INFO] {yesterday_str_hyphen}ã®Boxã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯æ—¢ã«å®Œäº†ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")

        except Exception as e:
            print(f"[ERROR] ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œçŸ¥ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("\n[ã‚¹ãƒ†ãƒƒãƒ—2.5] ã‚¢ãƒ©ãƒ¼ãƒˆæ¤œçŸ¥ã‚’ã‚¹ã‚­ãƒƒãƒ— (ALERT_ENABLED=0)")

    # ã‚¹ãƒ†ãƒƒãƒ—3: Netlifyã¸ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€å¹³æ—¥ã®ã¿ï¼‰
    skip_netlify_deploy = os.getenv("SKIP_NETLIFY_DEPLOY", "").lower() in ("1", "true", "yes")

    # åœŸæ—¥ã¯Netlifyãƒ‡ãƒ—ãƒ­ã‚¤ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆNetlifyç„¡æ–™æ ç¯€ç´„ã®ãŸã‚ï¼‰
    is_weekend = datetime.now().weekday() >= 5  # 5=åœŸæ›œ, 6=æ—¥æ›œ

    if skip_netlify_deploy:
        print("\n[ã‚¹ãƒ†ãƒƒãƒ—3] Netlifyã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’ã‚¹ã‚­ãƒƒãƒ— (SKIP_NETLIFY_DEPLOY=1)")
    elif is_weekend:
        print("\n[ã‚¹ãƒ†ãƒƒãƒ—3] Netlifyã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆåœŸæ—¥ã¯ç„¡æ–™æ ç¯€ç´„ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
    else:
        if dashboard_path.exists():
            try:
                import update_netlify_dashboard
                update_netlify_dashboard.deploy_to_netlify(
                    dashboard_path,
                    os.getenv("NETLIFY_SITE_ID", "47255fce-725c-48f1-a865-db146b183555")
                )
            except Exception as e:
                print(f"[WARNING] Netlify deploy failed: {e}")
                import traceback
                traceback.print_exc()
        else:
            print(f"\n[WARNING] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dashboard_path}")

    # ã‚¹ãƒ†ãƒƒãƒ—4: Cloudflare Pagesã¸ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    skip_cloudflare_deploy = os.getenv("SKIP_CLOUDFLARE_DEPLOY", "1").lower() in ("1", "true", "yes")

    if skip_cloudflare_deploy:
        print("\n[ã‚¹ãƒ†ãƒƒãƒ—4] Cloudflare Pagesã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’ã‚¹ã‚­ãƒƒãƒ— (SKIP_CLOUDFLARE_DEPLOY=1)")
    else:
        if dashboard_path.exists():
            try:
                import update_cloudflare_dashboard
                update_cloudflare_dashboard.deploy_to_cloudflare(
                    dashboard_path,
                    os.getenv("CLOUDFLARE_PAGES_PROJECT", "box-dashboard-report")
                )
            except Exception as e:
                print(f"[WARNING] Cloudflare Pages deploy failed: {e}")
                import traceback
                traceback.print_exc()
        else:
            print(f"\n[WARNING] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dashboard_path}")

    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    print("\n" + "=" * 80)
    print("[SUCCESS] Box Daily Update å®Œäº†")
    print(f"çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
    print("=" * 80)
    print("\nç”Ÿæˆã•ã‚ŒãŸãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰:")

    dashboard_output_dir = os.getenv("REPORT_OUTPUT_DIR", "C:\\box_reports")
    dashboard_path = Path(dashboard_output_dir) / "dashboard_period_allinone_full.html"
    if dashboard_path.exists():
        abs_path = dashboard_path.absolute()
        print(f"  {abs_path}")
        print(f"  file:///{str(abs_path).replace(chr(92), '/')}")
    else:
        print("  [WARNING] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    return 0


if __name__ == '__main__':
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n[INFO] ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(130)
    except Exception as e:
        print(f"\n[ERROR] äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
